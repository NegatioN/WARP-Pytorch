{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses\n",
    "\n",
    "> Where all the losses are situated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "def num_tries_gt_zero(scores, batch_size, max_trials, max_num, device):\n",
    "    '''\n",
    "    scores: [batch_size x N] float scores\n",
    "    returns: [batch_size x 1] the lowest indice per row where scores were first greater than 0. plus 1\n",
    "    '''\n",
    "    tmp = scores.gt(0).nonzero().t()\n",
    "    # We offset these values by 1 to look for unset values (zeros) later\n",
    "    values = tmp[1] + 1\n",
    "    # TODO just allocate normal zero-tensor and fill it?\n",
    "    # Sparse tensors can't be moved with .to() or .cuda() if you want to send in cuda variables first\n",
    "    if device.type == 'cuda':\n",
    "        t = torch.cuda.sparse.LongTensor(tmp, values, torch.Size((batch_size, max_trials+1))).to_dense()\n",
    "    else:\n",
    "        t = torch.sparse.LongTensor(tmp, values, torch.Size((batch_size, max_trials+1))).to_dense()\n",
    "    t[(t == 0)] += max_num # set all unused indices to be max possible number so its not picked by min() call\n",
    "\n",
    "    tries = torch.min(t, dim=1)[0]\n",
    "    return tries\n",
    "\n",
    "\n",
    "def warp_loss(positive_predictions, negative_predictions, num_labels, device):\n",
    "    '''\n",
    "    positive_predictions: [batch_size x 1] floats between -1 to 1\n",
    "    negative_predictions: [batch_size x N] floats between -1 to 1\n",
    "    num_labels: int total number of labels in dataset (not just the subset you're using for the batch)\n",
    "    device: pytorch.device\n",
    "    '''\n",
    "    batch_size, max_trials = negative_predictions.size(0), negative_predictions.size(1)\n",
    "\n",
    "    offsets, ones, max_num = (torch.arange(0, batch_size, 1).long().to(device) * (max_trials + 1),\n",
    "                              torch.ones(batch_size, 1).float().to(device),\n",
    "                              batch_size * (max_trials + 1) )\n",
    "\n",
    "    sample_scores = (1 + negative_predictions - positive_predictions)\n",
    "    # Add column of ones so we know when we used all our attempts, This is used for indexing and computing should_count_loss if no real value is above 0\n",
    "    sample_scores, negative_predictions = (torch.cat([sample_scores, ones], dim=1),\n",
    "                                           torch.cat([negative_predictions, ones], dim=1))\n",
    "\n",
    "    tries = num_tries_gt_zero(sample_scores, batch_size, max_trials, max_num, device)\n",
    "    attempts, trial_offset = tries.float(), (tries - 1) + offsets\n",
    "    loss_weights, should_count_loss = ( torch.log(torch.floor((num_labels - 1) / attempts)),\n",
    "                                        (attempts <= max_trials).float()) #Don't count loss if we used max number of attempts\n",
    "\n",
    "    losses = loss_weights * ((1 - positive_predictions.view(-1)) + negative_predictions.view(-1)[trial_offset]) * should_count_loss\n",
    "\n",
    "    return losses.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "cpu_device = torch.device('cpu')\n",
    "max_value = num_labels = 10\n",
    "\n",
    "## warp-loss tests\n",
    "def ground_truth(pos_val, neg_val, num_attempts=1, num_labels=10):\n",
    "    num_labels -= 1\n",
    "    loss_weight = np.log(np.floor(num_labels / float(num_attempts)))\n",
    "\n",
    "    return loss_weight * ((1-pos_val) + neg_val)\n",
    "\n",
    "comp_pos = torch.FloatTensor([[0.1], [0.9], [1]])\n",
    "comp_neg = torch.FloatTensor([[-1, 0.3, 0.5], [-1, -1, 0.3], [0.3, 0.5, -1]])\n",
    "comp_scores = (1 + comp_neg) - comp_pos\n",
    "\n",
    "def test_num_tries():\n",
    "    simple = torch.FloatTensor([[0.5, -0.5], [-0.5, 0.5]])\n",
    "    res = num_tries_gt_zero(simple, 2, 2, max_value, cpu_device)\n",
    "    ans = torch.LongTensor([1, 2])\n",
    "    for i, v in enumerate(res.long()):\n",
    "        assert v == ans[i]\n",
    "\n",
    "    res = num_tries_gt_zero(comp_scores, 3, 3, max_value, cpu_device)\n",
    "    ans = torch.LongTensor([2, 3, 1])\n",
    "    for i, v in enumerate(res.long()):\n",
    "        assert v == ans[i]\n",
    "\n",
    "\n",
    "def test_ground_truth():\n",
    "    # these variables should always trigger on first index\n",
    "    pos = torch.rand(2, 1).to(cpu_device)\n",
    "    neg = torch.rand(2, 3).to(cpu_device)\n",
    "    res = warp_loss(pos.view(-1, 1), neg, num_labels, cpu_device)\n",
    "\n",
    "    assert res == ground_truth(pos[0], neg[0][0], num_labels=num_labels) + ground_truth(pos[1], neg[1][0], num_labels=num_labels)\n",
    "\n",
    "    res = warp_loss(comp_pos.view(-1, 1), comp_neg, num_labels, cpu_device)\n",
    "\n",
    "    gt = np.sum(np.array([ground_truth(comp_pos[i], comp_neg[i][idx-1], num_attempts=idx, num_labels=num_labels)\n",
    "                            for i, idx in enumerate(num_tries_gt_zero(comp_scores, 3, 3, max_value, cpu_device))]))\n",
    "\n",
    "    assert np.allclose(res.data.numpy(), gt)\n",
    "\n",
    "def test_no_offending_scores():\n",
    "    pos = torch.FloatTensor([1, 1])\n",
    "    neg = torch.FloatTensor([[-1, -1, -1],[-1, -1, -1]])\n",
    "    res = warp_loss(pos.view(-1, 1), neg, num_labels, cpu_device)\n",
    "    \n",
    "    assert res == 0\n",
    "\n",
    "test_num_tries()\n",
    "test_ground_truth()\n",
    "test_no_offending_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
